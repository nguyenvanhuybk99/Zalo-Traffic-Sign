from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from cv2 import data
from torch.functional import split

import _init_paths

import os
import json
import glob
import cv2
import numpy as np
import time
from progress.bar import Bar
import torch
import matplotlib.pyplot as plt

from external.nms import soft_nms
from opts import opts
from logger import Logger
from utils.utils import AverageMeter
from datasets.dataset_factory import dataset_factory
from detectors.detector_factory import detector_factory

class PrefetchDataset(torch.utils.data.Dataset):
  class_name = [
        '__background__',
        "C\u1ea5m ng\u01b0\u1ee3c chi\u1ec1u",
        "C\u1ea5m d\u1eebng v\u00e0 \u0111\u1ed7",
        "C\u1ea5m r\u1ebd",
        "Gi\u1edbi h\u1ea1n t\u1ed1c \u0111\u1ed9",
        "C\u1ea5m c\u00f2n l\u1ea1i",
        "Nguy hi\u1ec3m",
        "Hi\u1ec7u l\u1ec7nh",]

  _valid_ids = [1, 2, 3, 4, 5, 6, 7]
  def __init__(self, opt, data_dir, pre_process_func):
    self.images = glob.glob(os.path.join(data_dir, '*.*'))
    # self.load_image_func = dataset.coco.loadImgs
    # self.img_dir = dataset.img_dir
    self.pre_process_func = pre_process_func
    self.opt = opt
  
  def __getitem__(self, index):
    img_path = self.images[index]
    # img_info = self.load_image_func(ids=[img_id])[0]
    # img_path = os.path.join(self.img_dir, img_info['file_name'])
    image = cv2.imread(img_path)
    images, meta = {}, {}
    for scale in opt.test_scales:
      if opt.task == 'ctdet':
        images[scale], meta[scale] = self.pre_process_func(image, scale)
    # flag, id = os.path.basename(img_path).split('.')[0].split('_')
    image_id = os.path.basename(img_path).split('.')[0]

    '''
    @return image: current image
    @return images: processed image with scale and inp
    @return meta: center, scale, out_height, out_width
    '''
    # if self.opt.debug_huy:
    #   print("images shape: ", images[1].shape)
    #   print("image shape:", image.shape)
    return int(image_id), {'images': images, 'image': image, 'meta': meta}


  def __len__(self):
    return len(self.images)

  def _to_float(self, x):
    return float("{:.2f}".format(x))

  def convert_eval_format(self, all_bboxes):
    # import pdb; pdb.set_trace()
    
    detections = []
    for image_id in all_bboxes:
      for cls_ind in all_bboxes[image_id]:
        category_id = self._valid_ids[cls_ind - 1]
        for bbox in all_bboxes[image_id][cls_ind]:
          bbox[2] -= bbox[0]
          bbox[3] -= bbox[1]
          score = bbox[4]
          bbox_out  = list(map(self._to_float, bbox[0:4]))
          # print(bbox_out)

          detection = {
              "image_id": int(image_id),
              "category_id": int(category_id),
              "bbox": bbox_out,
              "score": float("{:.2f}".format(score))
          }
          if len(bbox) > 5:
              extreme_points = list(map(self._to_float, bbox[5:13]))
              detection["extreme_points"] = extreme_points
          if score > 0:
            detections.append(detection)
    return detections

  def save_results(self, results, save_dir, split):
    json.dump(self.convert_eval_format(results),
                open('results/submission.json', 'w'), indent=4)
  
  def draw_label(self, boxes, image, img_id):
    thresh = 0.3
    print("img shape: ", image.shape)

    for cls_ind in boxes:
      category_id = self._valid_ids[cls_ind - 1]
      for bbox in boxes[cls_ind]:
        
        score = bbox[4]
        if score > thresh:
          cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
    if self.opt.debug_huy:
      
      cv2.imwrite(os.path.join(self.opt.debug_huy_dir, str(img_id) +'.jpg'), image)
      pass
def prefetch_test(opt):
  os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str

  Dataset = dataset_factory[opt.dataset]
  opt = opts().update_dataset_info_and_set_heads(opt, Dataset)
  Logger(opt)
  Detector = detector_factory[opt.task]

  split = 'test'
  data_dir = os.path.join(opt.data_dir)
  print(data_dir)
  detector = Detector(opt)
  dataset = PrefetchDataset(opt, data_dir, detector.pre_process)
  print('loading {} samples for testing'.format(len(dataset)))
  data_loader = torch.utils.data.DataLoader(
    dataset,
    batch_size=1, shuffle=False, num_workers=0, pin_memory=True)

  results = {}
  num_iters = len(dataset)
  bar = Bar('{}'.format(opt.exp_id), max=num_iters)
  time_stats = ['tot', 'load', 'pre', 'net', 'dec', 'post', 'merge']
  avg_time_stats = {t: AverageMeter() for t in time_stats}
  for ind, (img_id, pre_processed_images) in enumerate(data_loader):
    ret = detector.run(pre_processed_images)
    results[img_id.numpy().astype(np.int32)[0]] = ret['results']
    # print(results)
    Bar.suffix = '[{0}/{1}]|Tot: {total:} |ETA: {eta:} '.format(
                   ind, num_iters, total=bar.elapsed_td, eta=bar.eta_td)
    for t in avg_time_stats:
      avg_time_stats[t].update(ret[t])
      Bar.suffix = Bar.suffix + '|{} {tm.avg:.3f}s '.format(
        t, tm = avg_time_stats[t])
    bar.next()
    # print("img shape cur: ", pre_processed_images['image'].shape)
    # print(pre_processed_images['image'].numpy().shape)
    if opt.debug_huy:
      
      dataset.draw_label(ret['results'], pre_processed_images['image'].numpy()[0],
                         img_id.numpy().astype(np.int32)[0])
  bar.finish()
#   json.dumps(results, open('results_test.json'), indent=4)
  dataset.save_results(results, opt.save_dir, split)

if __name__ == '__main__':
  opt = opts().parse()
  prefetch_test(opt)
